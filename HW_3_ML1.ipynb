{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# LinearRegression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "\n",
    "results_regression = pd.DataFrame(columns = ['model', 'task', 'R2'])\n",
    "results_classification = pd.DataFrame(columns = ['model', 'task', 'f1', 'accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('boston.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'StandardScaler' object has no attribute 'score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4917/1559430797.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mscaled_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# print(scaled_df[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'StandardScaler' object has no attribute 'score'"
     ]
    }
   ],
   "source": [
    "# mses = []\n",
    "# lstat_coef = range(-20, 23)\n",
    "# target = data.MEDV\n",
    "\n",
    "# for coef in lstat_coef:\n",
    "#     pred_values = np.array([coef * lstat for lstat in data.LSTAT.values])\n",
    "#     print(pred_values)\n",
    "#     mses.append(np.sum((target - pred_values)**2))\n",
    "    \n",
    "# print(max(data.LSTAT))\n",
    "# print(mses)\n",
    "# plt.plot(lstat_coef, mses);\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data) \n",
    "scaled_df = scaler.score()\n",
    "print(scaled_df)\n",
    "# print(scaled_df[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Разделите выборку на обучающую и тестовую в отношении 80%/20%, предварительно выделив целевую переменную (колонка 'MEDV')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Ваш код ###\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = data[\"MEDV\"]\n",
    "X = data.drop(columns=[\"MEDV\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state = 10, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Обучите стандартную регрессию, а также Ridge и  Lasso с параметрами по умолчанию и выведите их R2 на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   model   task        R2\n",
      "0     LR  task2  0.670642\n",
      "1  Ridge  task2  0.665291\n",
      "2  Lasso  task2  0.534676\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LinearRegression # Линейная регресси\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "### Ваш код ###\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "# lr_y_pred = lr_model.predict(X_test)\n",
    "\n",
    "ridge_model = Ridge()\n",
    "ridge_model.fit(X_train, y_train)\n",
    "# ridge_y_pred = ridge_model.predict(X_test)\n",
    "\n",
    "lasso_model = Lasso()\n",
    "lasso_model.fit(X_train, y_train)\n",
    "# lasso_y_pred = lasso_model.predict(X_test)\n",
    "\n",
    "# https://scikit-learn.ru/3-1-cross-validation-evaluating-estimator-performance/\n",
    "# https://datafinder.ru/products/ocenka-r2-v-mashinnom-obuchenii#:~:text=%D0%9E%D1%86%D0%B5%D0%BD%D0%BA%D0%B0%20R2%20%E2%80%93%20%D0%BE%D1%87%D0%B5%D0%BD%D1%8C%20%D0%B2%D0%B0%D0%B6%D0%BD%D1%8B%D0%B9%20%D0%BF%D0%BE%D0%BA%D0%B0%D0%B7%D0%B0%D1%82%D0%B5%D0%BB%D1%8C,%D0%B2%20%D0%BF%D1%80%D0%BE%D0%B3%D0%BD%D0%BE%D0%B7%D0%B0%D1%85%2C%20%D0%BE%D0%B1%D1%8A%D1%8F%D1%81%D0%BD%D0%B5%D0%BD%D0%BD%D1%8B%D1%85%20%D0%BD%D0%B0%D0%B1%D0%BE%D1%80%D0%BE%D0%BC%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85.\n",
    "# Calculation of R2 Score\n",
    "r2_lr = lr_model.score(X_test, y_test) #cross_val_score(lr_model, X_test, y_test, cv=KFold(n_splits=3), scoring=\"r2\").mean()\n",
    "r2_ridge = ridge_model.score(X_test, y_test) #cross_val_score(ridge_model, X_test, y_test, cv=KFold(n_splits=3), scoring=\"r2\").mean()\n",
    "r2_lasso = lasso_model.score(X_test, y_test) #cross_val_score(lasso_model, X_test, y_test, cv=KFold(n_splits=3), scoring=\"r2\").mean() \n",
    "\n",
    "results_regression.loc[0] = ['LR', 'task2', r2_lr]\n",
    "results_regression.loc[1] = ['Ridge', 'task2', r2_ridge]\n",
    "results_regression.loc[2] = ['Lasso', 'task2', r2_lasso]\n",
    "print(results_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Для Ridge и Lasso подберите коэффициент регуляризации двумя способами 1) GridSearchCV, 2) RidgeCV и LassoCV, в пределах от $10^{-5}$ до $10^5$ (по степеням 10). Посчитайте R2 на тестовой выборке по всем моделям и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['alpha', 'copy_X', 'fit_intercept', 'max_iter', 'normalize', 'positive', 'random_state', 'solver', 'tol'])\n",
      "                model   task        R2\n",
      "0                  LR  task2  0.670642\n",
      "1               Ridge  task2  0.665291\n",
      "2               Lasso  task2  0.534676\n",
      "3  Ridge_GridSearchCV  task3  0.670002\n",
      "4             RidgeCV  task3  0.670002\n",
      "5  Lasso_GridSearchCV  task3  0.670360\n",
      "6             LassoCV  task3  0.670360\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# https://medium.com/nuances-of-programming/%D0%BB%D0%B0%D1%81%D1%81%D0%BE-%D0%B8-%D1%80%D0%B8%D0%B4%D0%B6-%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D0%B8-%D0%B8%D0%BD%D1%82%D1%83%D0%B8%D1%82%D0%B8%D0%B2%D0%BD%D0%BE%D0%B5-%D1%81%D1%80%D0%B0%D0%B2%D0%BD%D0%B5%D0%BD%D0%B8%D0%B5-a542dd761f62\n",
    "### Ваш код ###\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "# Defining grid of candidate alpha values (powers of 10, from 0.00001 to 1000000)\n",
    "param_grid = {\"alpha\": 10.0 ** np.arange(-5, 6)}\n",
    "\n",
    "# Initializing Ridge and GridSearchCV estimators\n",
    "ridge = Ridge()\n",
    "print(ridge.get_params().keys())\n",
    "grid_search = GridSearchCV(estimator=ridge, param_grid=param_grid)\n",
    "# Fitting grid search object\n",
    "grid_search.fit(X_train, y_train)\n",
    "r2_ridge_grid_search = grid_search.score(X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "ridge_reg_cv = RidgeCV(alphas=param_grid['alpha'], cv=5)\n",
    "ridge_reg_cv.fit(X_train, y_train)\n",
    "r2_ridge_cv = ridge_reg_cv.score(X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "# Initializing Lasso and GridSearchCV estimators\n",
    "lasso = Lasso()\n",
    "grid_search_lasso = GridSearchCV(estimator=lasso, param_grid=param_grid)\n",
    "# Fitting grid search object\n",
    "grid_search_lasso.fit(X_train, y_train)\n",
    "r2_lasso_grid_search = grid_search_lasso.score(X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "lasso_reg_cv = LassoCV(alphas=param_grid['alpha'], cv=5)\n",
    "lasso_reg_cv.fit(X_train, y_train)\n",
    "\n",
    "r2_lasso_cv = lasso_reg_cv.score(X_test, y_test)\n",
    "\n",
    "\n",
    "results_regression.loc[3] = ['Ridge_GridSearchCV', 'task3', r2_ridge_grid_search]\n",
    "results_regression.loc[4] = ['RidgeCV', 'task3', r2_ridge_cv]\n",
    "results_regression.loc[5] = ['Lasso_GridSearchCV', 'task3', r2_lasso_grid_search]\n",
    "results_regression.loc[6] = ['LassoCV', 'task3', r2_lasso_cv]\n",
    "print(results_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Проведите масштабирование выборки (используйте Pipeline, StandardScaler, MinMaxScaler), посчитайте R2 для Ridge и Lasso с параметрами по умолчанию и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   model   task        R2\n",
      "0                     LR  task2  0.670642\n",
      "1                  Ridge  task2  0.665291\n",
      "2                  Lasso  task2  0.534676\n",
      "3     Ridge_GridSearchCV  task3  0.670002\n",
      "4                RidgeCV  task3  0.670002\n",
      "5     Lasso_GridSearchCV  task3  0.670360\n",
      "6                LassoCV  task3  0.670360\n",
      "7   Ridge_StandardScaler  task4  0.670844\n",
      "8     Ridge_MinMaxScaler  task4  0.666259\n",
      "9   Lasso_StandardScaler  task4  0.608150\n",
      "10    Lasso_MinMaxScaler  task4  0.094319\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "### Ваш код ###\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "estimators = [('scaler', StandardScaler()), ('model', Ridge())]\n",
    "pipe = Pipeline(estimators)\n",
    "r2_ridge_standart_scaler = pipe.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "estimators = [('scaler', MinMaxScaler()), ('model', Ridge())]\n",
    "pipe = Pipeline(estimators)\n",
    "r2_ridge_min_max_scaler = pipe.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "estimators = [('scaler', StandardScaler()), ('model', Lasso())]\n",
    "pipe = Pipeline(estimators)\n",
    "r2_lasso_standart_scaler = pipe.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "estimators = [('scaler', MinMaxScaler()), ('model', Lasso())]\n",
    "pipe = Pipeline(estimators)\n",
    "r2_lasso_min_max_scaler = pipe.fit(X_train, y_train).score(X_test, y_test)\n",
    "results_regression.loc[7] = ['Ridge_StandardScaler', 'task4', r2_ridge_standart_scaler]\n",
    "results_regression.loc[8] = ['Ridge_MinMaxScaler', 'task4', r2_ridge_min_max_scaler]\n",
    "results_regression.loc[9] = ['Lasso_StandardScaler', 'task4', r2_lasso_standart_scaler]\n",
    "results_regression.loc[10] = ['Lasso_MinMaxScaler', 'task4', r2_lasso_min_max_scaler]\n",
    "print(results_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Подберите коэффициент регуляризации для Ridge и Lasso на масштабированных данных, посчитайте R2 и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      model   task        R2\n",
      "0                        LR  task2  0.670642\n",
      "1                     Ridge  task2  0.665291\n",
      "2                     Lasso  task2  0.534676\n",
      "3        Ridge_GridSearchCV  task3  0.670002\n",
      "4                   RidgeCV  task3  0.670002\n",
      "5        Lasso_GridSearchCV  task3  0.670360\n",
      "6                   LassoCV  task3  0.670360\n",
      "7      Ridge_StandardScaler  task4  0.670844\n",
      "8        Ridge_MinMaxScaler  task4  0.666259\n",
      "9      Lasso_StandardScaler  task4  0.608150\n",
      "10       Lasso_MinMaxScaler  task4  0.094319\n",
      "11  Ridge_StandardScaler_CV  task5  0.671640\n",
      "12    Ridge_MinMaxScaler_CV  task5  0.670629\n",
      "13  Lasso_StandardScaler_CV  task5  0.671214\n",
      "14    Lasso_MinMaxScaler_CV  task5  0.671900\n"
     ]
    }
   ],
   "source": [
    "# print_metrics\n",
    "# plot_prediction\n",
    "\n",
    "### Ваш код ###\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('model', Ridge())])\n",
    "params = { 'model__alpha': 10.0 ** np.arange(-5, 6) }\n",
    "grid_pipeline = GridSearchCV(pipe, params)\n",
    "r2_ridge_standart_scaler_cv = grid_pipeline.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()), ('model', Ridge())])\n",
    "params = { 'model__alpha': 10.0 ** np.arange(-5, 6) }\n",
    "grid_pipeline = GridSearchCV(pipe, params)\n",
    "r2_ridge_min_max_scaler_cv = grid_pipeline.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('model', Lasso())])\n",
    "params = { 'model__alpha': 10.0 ** np.arange(-5, 6) }\n",
    "grid_pipeline = GridSearchCV(pipe, params)\n",
    "r2_lasso_standart_scaler_cv = grid_pipeline.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()), ('model', Lasso())])\n",
    "params = { 'model__alpha': 10.0 ** np.arange(-5, 6) }\n",
    "grid_pipeline = GridSearchCV(pipe, params)\n",
    "r2_lasso_min_max_scaler_cv = grid_pipeline.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "results_regression.loc[11] = ['Ridge_StandardScaler_CV', 'task5', r2_ridge_standart_scaler_cv]\n",
    "results_regression.loc[12] = ['Ridge_MinMaxScaler_CV', 'task5', r2_ridge_min_max_scaler_cv]\n",
    "results_regression.loc[13] = ['Lasso_StandardScaler_CV', 'task5', r2_lasso_standart_scaler_cv]\n",
    "results_regression.loc[14] = ['Lasso_MinMaxScaler_CV', 'task5', r2_lasso_min_max_scaler_cv]\n",
    "print(results_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Добавьте попарные произведения признаков и их квадраты (используйте PolynomialFeatures) на масштабированных признаках, посчитайте R2 для Ridge и Lasso с параметрами по умолчанию и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        model   task        R2\n",
      "0                          LR  task2  0.670642\n",
      "1                       Ridge  task2  0.665291\n",
      "2                       Lasso  task2  0.534676\n",
      "3          Ridge_GridSearchCV  task3  0.670002\n",
      "4                     RidgeCV  task3  0.670002\n",
      "5          Lasso_GridSearchCV  task3  0.670360\n",
      "6                     LassoCV  task3  0.670360\n",
      "7        Ridge_StandardScaler  task4  0.670844\n",
      "8          Ridge_MinMaxScaler  task4  0.666259\n",
      "9        Lasso_StandardScaler  task4  0.608150\n",
      "10         Lasso_MinMaxScaler  task4  0.094319\n",
      "11    Ridge_StandardScaler_CV  task5  0.671640\n",
      "12      Ridge_MinMaxScaler_CV  task5  0.670629\n",
      "13    Lasso_StandardScaler_CV  task5  0.671214\n",
      "14      Lasso_MinMaxScaler_CV  task5  0.671900\n",
      "15  Ridge_StandardScaler_Poly  task6  0.877763\n",
      "16    Ridge_MinMaxScaler_Poly  task6  0.825928\n",
      "17  Lasso_StandardScaler_Poly  task6  0.748369\n",
      "18    Lasso_MinMaxScaler_Poly  task6  0.089644\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "### Ваш код ###\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('poly', PolynomialFeatures()), ('model', Ridge())])\n",
    "r2_ridge_standart_scaler_poly = pipe.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()), ('poly', PolynomialFeatures()), ('model', Ridge())])\n",
    "r2_ridge_min_max_scaler_poly = pipe.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('poly', PolynomialFeatures()), ('model', Lasso())])\n",
    "r2_lasso_standart_scaler_poly = pipe.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()), ('poly', PolynomialFeatures()), ('model', Lasso())])\n",
    "r2_lasso_min_max_scaler_poly = pipe.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "\n",
    "results_regression.loc[15] = ['Ridge_StandardScaler_Poly', 'task6', r2_ridge_standart_scaler_poly]\n",
    "results_regression.loc[16] = ['Ridge_MinMaxScaler_Poly', 'task6', r2_ridge_min_max_scaler_poly]\n",
    "results_regression.loc[17] = ['Lasso_StandardScaler_Poly', 'task6', r2_lasso_standart_scaler_poly]\n",
    "results_regression.loc[18] = ['Lasso_MinMaxScaler_Poly', 'task6', r2_lasso_min_max_scaler_poly]\n",
    "print(results_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Подберите коэффициент регуляризации для Ridge и Lasso на масштабированных данных, добавив PolynomialFeatures, посчитайте R2 и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.495e+02, tolerance: 2.514e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.146e+02, tolerance: 2.574e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.237e+02, tolerance: 2.353e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.350e+02, tolerance: 2.483e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.224e+02, tolerance: 2.507e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.176e+02, tolerance: 2.514e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.085e+02, tolerance: 2.574e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.963e+02, tolerance: 2.353e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.174e+02, tolerance: 2.483e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.036e+02, tolerance: 2.507e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.540e+02, tolerance: 2.514e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.809e+02, tolerance: 2.574e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.445e+02, tolerance: 2.353e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.491e+02, tolerance: 2.483e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.699e+02, tolerance: 2.507e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.440e+01, tolerance: 2.483e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.566e+02, tolerance: 2.514e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.174e+02, tolerance: 2.574e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.928e+02, tolerance: 2.353e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.322e+02, tolerance: 2.483e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.071e+02, tolerance: 2.507e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.728e+02, tolerance: 2.514e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.271e+02, tolerance: 2.574e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.819e+02, tolerance: 2.353e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.307e+02, tolerance: 2.483e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.133e+02, tolerance: 2.507e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.942e+02, tolerance: 2.514e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.024e+02, tolerance: 2.574e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.604e+02, tolerance: 2.353e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.892e+02, tolerance: 2.483e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.958e+02, tolerance: 2.507e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.675e+00, tolerance: 2.514e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.817e+01, tolerance: 2.574e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.101e+00, tolerance: 2.483e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           model   task        R2\n",
      "0                             LR  task2  0.670642\n",
      "1                          Ridge  task2  0.665291\n",
      "2                          Lasso  task2  0.534676\n",
      "3             Ridge_GridSearchCV  task3  0.670002\n",
      "4                        RidgeCV  task3  0.670002\n",
      "5             Lasso_GridSearchCV  task3  0.670360\n",
      "6                        LassoCV  task3  0.670360\n",
      "7           Ridge_StandardScaler  task4  0.670844\n",
      "8             Ridge_MinMaxScaler  task4  0.666259\n",
      "9           Lasso_StandardScaler  task4  0.608150\n",
      "10            Lasso_MinMaxScaler  task4  0.094319\n",
      "11       Ridge_StandardScaler_CV  task5  0.671640\n",
      "12         Ridge_MinMaxScaler_CV  task5  0.670629\n",
      "13       Lasso_StandardScaler_CV  task5  0.671214\n",
      "14         Lasso_MinMaxScaler_CV  task5  0.671900\n",
      "15     Ridge_StandardScaler_Poly  task6  0.877763\n",
      "16       Ridge_MinMaxScaler_Poly  task6  0.825928\n",
      "17     Lasso_StandardScaler_Poly  task6  0.748369\n",
      "18       Lasso_MinMaxScaler_Poly  task6  0.089644\n",
      "19  Ridge_StandardScaler_Poly_CV  task7  0.866597\n",
      "20    Ridge_MinMaxScaler_Poly_CV  task7  0.868587\n",
      "21  Lasso_StandardScaler_Poly_CV  task7  0.852894\n",
      "22    Lasso_MinMaxScaler_Poly_CV  task7  0.840998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.853e+01, tolerance: 3.109e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "### Ваш код ###\n",
    "\n",
    "params = { 'model__alpha': 10.0 ** np.arange(-5, 6) }\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('poly', PolynomialFeatures()), ('model', Ridge())])\n",
    "grid_pipeline = GridSearchCV(pipe, params)\n",
    "r2_ridge_standart_scaler_poly_cv = grid_pipeline.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()), ('poly', PolynomialFeatures()), ('model', Ridge())])\n",
    "grid_pipeline = GridSearchCV(pipe, params)\n",
    "r2_ridge_min_max_scaler_poly_cv = grid_pipeline.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('poly', PolynomialFeatures()), ('model', Lasso())])\n",
    "grid_pipeline = GridSearchCV(pipe, params)\n",
    "r2_lasso_standart_scaler_poly_cv = grid_pipeline.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()), ('poly', PolynomialFeatures()), ('model', Lasso())])\n",
    "grid_pipeline = GridSearchCV(pipe, params)\n",
    "r2_lasso_min_max_scaler_poly_cv = grid_pipeline.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "\n",
    "results_regression.loc[19] = ['Ridge_StandardScaler_Poly_CV', 'task7', r2_ridge_standart_scaler_poly_cv]\n",
    "results_regression.loc[20] = ['Ridge_MinMaxScaler_Poly_CV', 'task7', r2_ridge_min_max_scaler_poly_cv]\n",
    "results_regression.loc[21] = ['Lasso_StandardScaler_Poly_CV', 'task7', r2_lasso_standart_scaler_poly_cv]\n",
    "results_regression.loc[22] = ['Lasso_MinMaxScaler_Poly_CV', 'task7', r2_lasso_min_max_scaler_poly_cv]\n",
    "print(results_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Подберите наилучшую модель (используйте Pipeline, GridSearchCV) подбирая тип регуляризации (L1,L2), коэффициент регуляризации, метод масштабирования и степень полинома в PolynomialFeatures. Выведите итоговые параметры и результат R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.495e+02, tolerance: 2.514e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.146e+02, tolerance: 2.574e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.237e+02, tolerance: 2.353e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.350e+02, tolerance: 2.483e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.224e+02, tolerance: 2.507e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.176e+02, tolerance: 2.514e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.085e+02, tolerance: 2.574e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.963e+02, tolerance: 2.353e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.174e+02, tolerance: 2.483e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.036e+02, tolerance: 2.507e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.540e+02, tolerance: 2.514e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.809e+02, tolerance: 2.574e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.445e+02, tolerance: 2.353e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.491e+02, tolerance: 2.483e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.699e+02, tolerance: 2.507e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.440e+01, tolerance: 2.483e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Параметры лучшей модели:\n",
      " {'cv': 'GridSearchCV', 'scaler': 'MinMaxScaler', 'model': 'Ridge(L2)', 'best_aplha': {'model__alpha': 0.1}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "### Ваш код ###\n",
    "params = { 'model__alpha': 10.0 ** np.arange(-5, 6) }\n",
    "\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('poly', PolynomialFeatures()), ('model', Lasso())])\n",
    "grid_pipeline = GridSearchCV(pipe, params)\n",
    "r2_lasso_standart_scaler_poly_cv = grid_pipeline.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "best_params = { \"cv\": 'GridSearchCV', \"scaler\": 'MinMaxScaler', \"model\": 'Ridge(L2)', \"best_aplha\": grid_pipeline.best_params_}\n",
    "\n",
    "\n",
    "print('Параметры лучшей модели:\\n', best_params)\n",
    "r2_best_model = 0\n",
    "results_regression.loc[23] = ['Best_Model', 'task8', r2_best_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>task</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>task2</td>\n",
       "      <td>0.670642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>task2</td>\n",
       "      <td>0.665291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>task2</td>\n",
       "      <td>0.534676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ridge_GridSearchCV</td>\n",
       "      <td>task3</td>\n",
       "      <td>0.670002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>task3</td>\n",
       "      <td>0.670002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lasso_GridSearchCV</td>\n",
       "      <td>task3</td>\n",
       "      <td>0.670360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LassoCV</td>\n",
       "      <td>task3</td>\n",
       "      <td>0.670360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ridge_StandardScaler</td>\n",
       "      <td>task4</td>\n",
       "      <td>0.670844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ridge_MinMaxScaler</td>\n",
       "      <td>task4</td>\n",
       "      <td>0.666259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lasso_StandardScaler</td>\n",
       "      <td>task4</td>\n",
       "      <td>0.608150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lasso_MinMaxScaler</td>\n",
       "      <td>task4</td>\n",
       "      <td>0.094319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ridge_StandardScaler_CV</td>\n",
       "      <td>task5</td>\n",
       "      <td>0.671640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Ridge_MinMaxScaler_CV</td>\n",
       "      <td>task5</td>\n",
       "      <td>0.670629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lasso_StandardScaler_CV</td>\n",
       "      <td>task5</td>\n",
       "      <td>0.671214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lasso_MinMaxScaler_CV</td>\n",
       "      <td>task5</td>\n",
       "      <td>0.671900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ridge_StandardScaler_Poly</td>\n",
       "      <td>task6</td>\n",
       "      <td>0.877763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ridge_MinMaxScaler_Poly</td>\n",
       "      <td>task6</td>\n",
       "      <td>0.825928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Lasso_StandardScaler_Poly</td>\n",
       "      <td>task6</td>\n",
       "      <td>0.748369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Lasso_MinMaxScaler_Poly</td>\n",
       "      <td>task6</td>\n",
       "      <td>0.089644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Ridge_StandardScaler_Poly_CV</td>\n",
       "      <td>task7</td>\n",
       "      <td>0.866597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Ridge_MinMaxScaler_Poly_CV</td>\n",
       "      <td>task7</td>\n",
       "      <td>0.868587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Lasso_StandardScaler_Poly_CV</td>\n",
       "      <td>task7</td>\n",
       "      <td>0.852894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Lasso_MinMaxScaler_Poly_CV</td>\n",
       "      <td>task7</td>\n",
       "      <td>0.840998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Best_Model</td>\n",
       "      <td>task8</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           model   task        R2\n",
       "0                             LR  task2  0.670642\n",
       "1                          Ridge  task2  0.665291\n",
       "2                          Lasso  task2  0.534676\n",
       "3             Ridge_GridSearchCV  task3  0.670002\n",
       "4                        RidgeCV  task3  0.670002\n",
       "5             Lasso_GridSearchCV  task3  0.670360\n",
       "6                        LassoCV  task3  0.670360\n",
       "7           Ridge_StandardScaler  task4  0.670844\n",
       "8             Ridge_MinMaxScaler  task4  0.666259\n",
       "9           Lasso_StandardScaler  task4  0.608150\n",
       "10            Lasso_MinMaxScaler  task4  0.094319\n",
       "11       Ridge_StandardScaler_CV  task5  0.671640\n",
       "12         Ridge_MinMaxScaler_CV  task5  0.670629\n",
       "13       Lasso_StandardScaler_CV  task5  0.671214\n",
       "14         Lasso_MinMaxScaler_CV  task5  0.671900\n",
       "15     Ridge_StandardScaler_Poly  task6  0.877763\n",
       "16       Ridge_MinMaxScaler_Poly  task6  0.825928\n",
       "17     Lasso_StandardScaler_Poly  task6  0.748369\n",
       "18       Lasso_MinMaxScaler_Poly  task6  0.089644\n",
       "19  Ridge_StandardScaler_Poly_CV  task7  0.866597\n",
       "20    Ridge_MinMaxScaler_Poly_CV  task7  0.868587\n",
       "21  Lasso_StandardScaler_Poly_CV  task7  0.852894\n",
       "22    Lasso_MinMaxScaler_Poly_CV  task7  0.840998\n",
       "23                    Best_Model  task8  0.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://archive.ics.uci.edu/ml/datasets/Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<=50K' '>50K']\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('adult.csv')\n",
    "print(data['class'].unique())#.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Разделите выборку на признаки и целевую переменную(колонка class). Замените целевую переменную на числовые значения ('<=50K' - 1, '>50K' - 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Ваш код ###\n",
    "data[\"class-num\"] = np.where(data[\"class\"] == \"<=50K\", 1, 0)\n",
    "y = data[\"class-num\"]\n",
    "X = data.drop(columns=[\"class\", \"class-num\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state = 10, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Посчитайте метрики accuracy и f1_score на предсказании только самого частого класса в целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37155\n",
      "11687\n",
      "                 model    task        f1  accuracy\n",
      "0  Most Frequent class  task10  0.864899  0.761958\n"
     ]
    }
   ],
   "source": [
    "#Определить самый часто встречающийся класс 1 или 0.\n",
    "#Обучить модель фитом как обычно // треин тест сплит на отфильтрованой выборке самого частого класса\n",
    "#на том что получилось найти аккураси и ф1 скор\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "### Ваш код ###\n",
    "print(len(data[data[\"class-num\"] == 1]))\n",
    "print(len(data[data[\"class-num\"] == 0]))\n",
    "# Самый частый класс - 1\n",
    "# most_frequent_class = data[data[\"class-num\"] == 1] # сделали датасет только с самым частым классом\n",
    "# y_most_frequent = most_frequent_class[\"class-num\"] # целевая переменная\n",
    "# X_most_frequent = most_frequent_class.drop(columns=[\"class\", \"class-num\"]) # признаки с самым частым классом\n",
    "\n",
    "# params = { 'model__alpha': 10.0 ** np.arange(-5, 6) }\n",
    "\n",
    "# pipe = Pipeline([('scaler', MinMaxScaler()), ('poly', PolynomialFeatures()), ('model', Ridge())])\n",
    "# grid_pipeline = GridSearchCV(pipe, params)\n",
    "# grid_pipeline.fit(X_train, y_train) # обучение модели\n",
    "# y_pred_mf = grid_pipelinve.predict(X_most_frequent) # предсказание самого частого класса\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# X_train_most_frequent = X_test[X_test[\"class-num\"] == 1]\n",
    "# y_train_most_frequent = y_test[y_test[\"class-num\"] == 1]\n",
    "\n",
    "# print([1] * len(y_train))\n",
    "\n",
    "f1_most_frequent = f1_score(y_train, [1] * len(y_train))\n",
    "acc_most_frequent = accuracy_score(y_train, [1] * len(y_train))\n",
    "results_classification.loc[0] = ['Most Frequent class', 'task10', f1_most_frequent, acc_most_frequent]\n",
    "print(results_classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Выясните, присутствуют ли в данных пропуски. Если присутствуют, заполните их самыми частыми значениями (испольуйте SimpleImputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [age, workclass, fnlwgt, education, education-num, marital-status, occupation, relationship, race, sex, capital-gain, capital-loss, hours-per-week, native-country]\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# columns_with_nulls = [\"workclass\", \"occupation\", \"native-country\"]\n",
    "# data[data[\"native-country\"] == '?']\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(missing_values='?', strategy=\"most_frequent\", copy=False)\n",
    "X[\"workclass\"] = imp.fit_transform(X[\"workclass\"].values.reshape(-1,1))[:,0]\n",
    "X[\"occupation\"] = imp.fit_transform(X[\"occupation\"].values.reshape(-1,1))[:,0]\n",
    "X[\"native-country\"] = imp.fit_transform(X[\"native-country\"].values.reshape(-1,1))[:,0]\n",
    "\n",
    "X[X[\"native-country\"] == '?']\n",
    "# data.dropna()\n",
    "### Ваш код ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Выберите колонки с числовыми и категориальными переменными (используя возможности pandas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 16 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             48842 non-null  int64 \n",
      " 1   workclass       48842 non-null  object\n",
      " 2   fnlwgt          48842 non-null  int64 \n",
      " 3   education       48842 non-null  object\n",
      " 4   education-num   48842 non-null  int64 \n",
      " 5   marital-status  48842 non-null  object\n",
      " 6   occupation      48842 non-null  object\n",
      " 7   relationship    48842 non-null  object\n",
      " 8   race            48842 non-null  object\n",
      " 9   sex             48842 non-null  object\n",
      " 10  capital-gain    48842 non-null  int64 \n",
      " 11  capital-loss    48842 non-null  int64 \n",
      " 12  hours-per-week  48842 non-null  int64 \n",
      " 13  native-country  48842 non-null  object\n",
      " 14  class           48842 non-null  object\n",
      " 15  class-num       48842 non-null  int64 \n",
      "dtypes: int64(7), object(9)\n",
      "memory usage: 6.0+ MB\n",
      "num columns: ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
      "category_columns: ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Ваш код ###\n",
    "data.info()\n",
    "numeric_cols = X_train.columns[X_train.dtypes == 'int64'].tolist()\n",
    "category_cols = X_train.columns[X_train.dtypes == 'object'].tolist()\n",
    "\n",
    "print(f'num columns: {numeric_cols}')\n",
    "print(f'category_columns: {category_cols}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Создайте пайплайн по обработке числовых и категориальных значений колонок (используйте OneHotEncoder,MinMaxScaler) и посчитайте cross_val_score по алгоритмам LogisticRegression, KNeighborsClassifier, LinearSVC по метрикам accuracy и f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t0.3835616438356165\n",
      "  (0, 1)\t0.1491677206704818\n",
      "  (0, 2)\t0.06666666666666667\n",
      "  (0, 5)\t0.39795918367346933\n",
      "  (0, 10)\t1.0\n",
      "  (0, 18)\t1.0\n",
      "  (0, 33)\t1.0\n",
      "  (0, 45)\t1.0\n",
      "  (0, 53)\t1.0\n",
      "  (0, 63)\t1.0\n",
      "  (0, 65)\t1.0\n",
      "  (0, 92)\t1.0\n",
      "  (1, 0)\t0.3698630136986301\n",
      "  (1, 1)\t0.13219103695016884\n",
      "  (1, 2)\t0.5333333333333333\n",
      "  (1, 5)\t0.39795918367346933\n",
      "  (1, 6)\t1.0\n",
      "  (1, 26)\t1.0\n",
      "  (1, 33)\t1.0\n",
      "  (1, 38)\t1.0\n",
      "  (1, 58)\t1.0\n",
      "  (1, 63)\t1.0\n",
      "  (1, 64)\t1.0\n",
      "  (1, 105)\t1.0\n",
      "  (2, 0)\t0.4246575342465753\n",
      "  :\t:\n",
      "  (39070, 105)\t1.0\n",
      "  (39071, 0)\t0.2191780821917808\n",
      "  (39071, 1)\t0.0086396715299802\n",
      "  (39071, 2)\t0.7333333333333334\n",
      "  (39071, 5)\t0.39795918367346933\n",
      "  (39071, 10)\t1.0\n",
      "  (39071, 22)\t1.0\n",
      "  (39071, 35)\t1.0\n",
      "  (39071, 46)\t1.0\n",
      "  (39071, 57)\t1.0\n",
      "  (39071, 59)\t1.0\n",
      "  (39071, 64)\t1.0\n",
      "  (39071, 105)\t1.0\n",
      "  (39072, 0)\t0.0273972602739726\n",
      "  (39072, 1)\t0.0567191727582219\n",
      "  (39072, 2)\t0.5333333333333333\n",
      "  (39072, 5)\t0.39795918367346933\n",
      "  (39072, 10)\t1.0\n",
      "  (39072, 26)\t1.0\n",
      "  (39072, 35)\t1.0\n",
      "  (39072, 43)\t1.0\n",
      "  (39072, 54)\t1.0\n",
      "  (39072, 63)\t1.0\n",
      "  (39072, 65)\t1.0\n",
      "  (39072, 105)\t1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 469, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\", line 748, in transform\n",
      "    Xs = self._fit_transform(\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\", line 606, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1046, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 876, in _transform_one\n",
      "    res = transformer.transform(X)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py\", line 509, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py\", line 142, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories ['Laos'] in column 7 during transform\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 469, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\", line 748, in transform\n",
      "    Xs = self._fit_transform(\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\", line 606, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1046, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 876, in _transform_one\n",
      "    res = transformer.transform(X)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py\", line 509, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py\", line 142, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories ['Never-worked'] in column 0 during transform\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 469, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\", line 748, in transform\n",
      "    Xs = self._fit_transform(\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\", line 606, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1046, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 876, in _transform_one\n",
      "    res = transformer.transform(X)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py\", line 509, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py\", line 142, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories ['Laos'] in column 7 during transform\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 469, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\", line 748, in transform\n",
      "    Xs = self._fit_transform(\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\", line 606, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1046, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 876, in _transform_one\n",
      "    res = transformer.transform(X)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py\", line 509, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py\", line 142, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories ['Never-worked'] in column 0 during transform\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 469, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\", line 748, in transform\n",
      "    Xs = self._fit_transform(\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\", line 606, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1046, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 876, in _transform_one\n",
      "    res = transformer.transform(X)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py\", line 509, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py\", line 142, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories ['Laos'] in column 7 during transform\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 469, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\", line 748, in transform\n",
      "    Xs = self._fit_transform(\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\", line 606, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1046, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 876, in _transform_one\n",
      "    res = transformer.transform(X)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py\", line 509, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py\", line 142, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories ['Never-worked'] in column 0 during transform\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 469, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\", line 748, in transform\n",
      "    Xs = self._fit_transform(\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\", line 606, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1046, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 876, in _transform_one\n",
      "    res = transformer.transform(X)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py\", line 509, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py\", line 142, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories ['Laos'] in column 7 during transform\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 469, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\", line 748, in transform\n",
      "    Xs = self._fit_transform(\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\", line 606, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1046, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 876, in _transform_one\n",
      "    res = transformer.transform(X)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py\", line 509, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py\", line 142, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories ['Never-worked'] in column 0 during transform\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 469, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\", line 748, in transform\n",
      "    Xs = self._fit_transform(\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\", line 606, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1046, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 876, in _transform_one\n",
      "    res = transformer.transform(X)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py\", line 509, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py\", line 142, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories ['Laos'] in column 7 during transform\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 469, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\", line 748, in transform\n",
      "    Xs = self._fit_transform(\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\", line 606, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1046, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 876, in _transform_one\n",
      "    res = transformer.transform(X)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py\", line 509, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py\", line 142, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories ['Never-worked'] in column 0 during transform\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 469, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\", line 748, in transform\n",
      "    Xs = self._fit_transform(\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\", line 606, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1046, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 876, in _transform_one\n",
      "    res = transformer.transform(X)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py\", line 509, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py\", line 142, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories ['Laos'] in column 7 during transform\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  model    task  \\\n",
      "0   Most Frequent class  task10   \n",
      "1    LogisticRegression  task13   \n",
      "2  KNeighborsClassifier  task13   \n",
      "3             LinearSVC  task13   \n",
      "\n",
      "                                                  f1  \\\n",
      "0                                           0.864899   \n",
      "1  [nan, 0.8978653530377668, 0.8955901426718547, ...   \n",
      "2  [nan, 0.8794373744139318, 0.8829300196206671, ...   \n",
      "3  [nan, 0.9031413612565444, 0.9032467532467534, ...   \n",
      "\n",
      "                                            accuracy  \n",
      "0                                           0.761958  \n",
      "1  [nan, 0.8408393039918116, 0.8352098259979529, ...  \n",
      "2  [nan, 0.8157625383828045, 0.8167860798362334, ...  \n",
      "3  [nan, 0.8485158648925282, 0.8474923234390993, ...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 469, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\", line 748, in transform\n",
      "    Xs = self._fit_transform(\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\", line 606, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1046, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 876, in _transform_one\n",
      "    res = transformer.transform(X)\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py\", line 509, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "  File \"/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py\", line 142, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories ['Never-worked'] in column 0 during transform\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3162: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return asarray(a).ndim\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "### Ваш код ###\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/71715754/valueerror-specifying-the-columns-using-strings-is-only-supported-for-pandas-da\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numeric', MinMaxScaler(), numeric_cols),\n",
    "        ('categorical', OneHotEncoder(), category_cols)\n",
    "    ], remainder='passthrough'\n",
    ")\n",
    "\n",
    "\n",
    "X_output = preprocessor.fit_transform(X_train)\n",
    "print(X_output)\n",
    "logistic_regression = LogisticRegression()\n",
    "k_neighbors_classifier = KNeighborsClassifier()\n",
    "linear_svc = LinearSVC()\n",
    "\n",
    "pipeline_lr = Pipeline(steps=[('col_tra', ColumnTransformer(remainder='passthrough',\n",
    "                                             transformers=[('trf', MinMaxScaler(), numeric_cols),\n",
    "                                                           ('categorical', OneHotEncoder(), category_cols)])),\n",
    "               ('model', logistic_regression)])\n",
    "\n",
    "\n",
    "# pipeline_lr = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', logistic_regression)])\n",
    "\n",
    "pipeline_lr = make_pipeline(preprocessor, logistic_regression)\n",
    "pipeline_knn = make_pipeline(preprocessor, k_neighbors_classifier)\n",
    "pipeline_svm = make_pipeline(preprocessor, linear_svc)\n",
    "\n",
    "# pipeline_lr.fit(X_output, y_train)\n",
    "# pipeline_knn.fit(X_output, y_train)\n",
    "# pipeline_svm.fit(X_output, y_train)\n",
    "\n",
    "# scores_lr = cross_val_score(pipeline_lr, X_test, y_test, cv=5, scoring=['accuracy', 'f1'])\n",
    "# scores_knn = cross_val_score(pipeline_knn, X_test, y_test, cv=5, scoring=['accuracy', 'f1'])\n",
    "# scores_svm = cross_val_score(pipeline_svm, X_test, y_test, cv=5, scoring=['accuracy', 'f1'])\n",
    "\n",
    "# print(scores_lr)\n",
    "\n",
    "f1_LR = cross_val_score(pipeline_lr, X_test, y_test, cv=5, scoring='f1')\n",
    "acc_LR = cross_val_score(pipeline_lr, X_test, y_test, cv=5, scoring='accuracy')\n",
    "f1_KNN = cross_val_score(pipeline_knn, X_test, y_test, cv=5, scoring='f1')\n",
    "acc_KNN = cross_val_score(pipeline_knn, X_test, y_test, cv=5, scoring='accuracy')\n",
    "f1_SVM = cross_val_score(pipeline_svm, X_test, y_test, cv=5, scoring='f1')\n",
    "acc_SVM = cross_val_score(pipeline_svm, X_test, y_test, cv=5, scoring='accuracy')\n",
    "\n",
    "results_classification.loc[1] = ['LogisticRegression', 'task13', f1_LR, acc_LR]\n",
    "results_classification.loc[2] = ['KNeighborsClassifier', 'task13', f1_KNN, acc_KNN]\n",
    "results_classification.loc[3] = ['LinearSVC', 'task13', f1_SVM, acc_SVM]\n",
    "print(results_classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Можно заметить что в данных присутствуют значения '?', замените их самыми частыми значениями, (испольуйте SimpleImputer). Посчитайте cross_val_score по алгоритмам LogisticRegression, KNeighborsClassifier, LinearSVC по метрикам accuracy и f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Private'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4917/1480585277.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# knn_f1_scores = cross_val_score(knn_model, X_train, y_train, cv=5, scoring='f1')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# lin_svc_f1_scores = cross_val_score(lin_svc_model, X_train, y_train, cv=5, scoring='f1')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mlog_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mf1_LR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0macc_LR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1506\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1508\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m   1509\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m    965\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    744\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m                 raise ValueError(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2064\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2066\u001b[0m     def __array_wrap__(\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Private'"
     ]
    }
   ],
   "source": [
    "### Ваш код ###\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Создание моделей\n",
    "log_model = LogisticRegression()\n",
    "knn_model = KNeighborsClassifier()\n",
    "lin_svc_model = LinearSVC()\n",
    "\n",
    "# Оценка моделей с помощью cross_val_score\n",
    "# log_scores = cross_val_score(log_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "# knn_scores = cross_val_score(knn_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "# lin_svc_scores = cross_val_score(lin_svc_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# # Оценка моделей с помощью cross_val_score и метрики f1_score\n",
    "# log_f1_scores = cross_val_score(log_model, X_train, y_train, cv=5, scoring='f1')\n",
    "# knn_f1_scores = cross_val_score(knn_model, X_train, y_train, cv=5, scoring='f1')\n",
    "# lin_svc_f1_scores = cross_val_score(lin_svc_model, X_train, y_train, cv=5, scoring='f1')\n",
    "log_model.fit(X_train, y_train)\n",
    "f1_LR = cross_val_score(log_model, X_test, y_train, scoring='f1')\n",
    "acc_LR = cross_val_score(log_model, X_train, y_train, scoring='accuracy')\n",
    "f1_KNN = cross_val_score(knn_model, X_train, y_train, scoring='f1')\n",
    "acc_KNN = cross_val_score(knn_model, X_train, y_train, scoring='accuracy')\n",
    "f1_SVM = cross_val_score(lin_svc_model, X_train, y_train, scoring='f1')\n",
    "acc_SVM = cross_val_score(lin_svc_model, X_train, y_train, scoring='accuracy')\n",
    "\n",
    "results_classification.loc[4] = ['LogisticRegression_impute', 'task14', f1_LR, acc_LR]\n",
    "results_classification.loc[5] = ['KNeighborsClassifier_impute', 'task14', f1_KNN, acc_KNN]\n",
    "results_classification.loc[6] = ['LinearSVC_impute', 'task14', f1_SVM, acc_SVM]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Посчитайте cross_val_score по тем же алгоритмам и метрикам, если просто удалить значения '?'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Ваш код ###\n",
    "\n",
    "f1_LR_del_missings = 0\n",
    "acc_LR_del_missings = 0\n",
    "f1_KNN_del_missings = 0\n",
    "acc_KNN_del_missings = 0\n",
    "f1_SVM_del_missings = 0\n",
    "acc_SVM_del_missings = 0\n",
    "results_classification.loc[7] = ['LogisticRegression_delete_missings', 'task15', f1_LR_del_missings, acc_LR_del_missings]\n",
    "results_classification.loc[8] = ['KNeighborsClassifier_delete_missings', 'task15', f1_KNN_del_missings, acc_KNN_del_missings]\n",
    "results_classification.loc[9] = ['LinearSVC_delete_missings', 'task15', f1_SVM_del_missings, acc_SVM_del_missings]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 16. Посчитайте cross_val_score для RandomForestClassifier,GradientBoostingClassifier на данных с замененными значениями '?' на самые частые значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Ваш код ###\n",
    "\n",
    "f1_RF = 0\n",
    "acc_RF = 0\n",
    "f1_GB = 0\n",
    "acc_GB = 0\n",
    "results_classification.loc[10] = ['RandomForestClassifier', 'task16', f1_RF, acc_RF]\n",
    "results_classification.loc[11] = ['GradientBoostingClassifier', 'task16', f1_GB, acc_GB]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. Подберите наилучшую модель, подбирая методы обработки колонок - масштабирование признаков, кодирование признаков и заполнение пропусков. Параметры алгоритмов оставьте по умолчанию. Выведите итоговые параметры и результат accuracy и f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Ваш код ###\n",
    "\n",
    "best_params = {}\n",
    "print('Параметры лучшей модели:\\n', best_params)\n",
    "f1_best = 0\n",
    "acc_best = 0\n",
    "results_classification.loc[12] = ['Best_Model', 'task17', f1_best, acc_best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'sparse_output'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8411/2920334343.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         (\n\u001b[1;32m     20\u001b[0m             \u001b[0;34m\"cat\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mcategorical_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         ),\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'sparse_output'"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X, y = fetch_openml(\n",
    "    \"titanic\", version=1, as_frame=True, return_X_y=True\n",
    ")\n",
    "numeric_features = [\"age\", \"fare\"]\n",
    "numeric_transformer = make_pipeline(SimpleImputer(strategy=\"median\"), StandardScaler())\n",
    "categorical_features = [\"embarked\", \"pclass\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\n",
    "            \"cat\",\n",
    "            OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False),\n",
    "            categorical_features,\n",
    "        ),\n",
    "    ],\n",
    "    verbose_feature_names_out=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
