{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "LinearRegression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "\n",
    "results_regression = pd.DataFrame(columns = ['model', 'task', 'R2'])\n",
    "results_classification = pd.DataFrame(columns = ['model', 'task', 'f1', 'accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('boston.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'StandardScaler' object has no attribute 'score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5135/1559430797.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mscaled_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# print(scaled_df[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'StandardScaler' object has no attribute 'score'"
     ]
    }
   ],
   "source": [
    "# mses = []\n",
    "# lstat_coef = range(-20, 23)\n",
    "# target = data.MEDV\n",
    "\n",
    "# for coef in lstat_coef:\n",
    "#     pred_values = np.array([coef * lstat for lstat in data.LSTAT.values])\n",
    "#     print(pred_values)\n",
    "#     mses.append(np.sum((target - pred_values)**2))\n",
    "    \n",
    "# print(max(data.LSTAT))\n",
    "# print(mses)\n",
    "# plt.plot(lstat_coef, mses);\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data) \n",
    "scaled_df = scaler.score()\n",
    "print(scaled_df)\n",
    "# print(scaled_df[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Разделите выборку на обучающую и тестовую в отношении 80%/20%, предварительно выделив целевую переменную (колонка 'MEDV')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Ваш код ###\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = data[\"MEDV\"]\n",
    "X = data.drop(columns=[\"MEDV\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state = 10, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Обучите стандартную регрессию, а также Ridge и  Lasso с параметрами по умолчанию и выведите их R2 на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   model   task        R2\n",
      "0     LR  task2  0.670642\n",
      "1  Ridge  task2  0.665291\n",
      "2  Lasso  task2  0.534676\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LinearRegression # Линейная регресси\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "### Ваш код ###\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "# lr_y_pred = lr_model.predict(X_test)\n",
    "\n",
    "ridge_model = Ridge()\n",
    "ridge_model.fit(X_train, y_train)\n",
    "# ridge_y_pred = ridge_model.predict(X_test)\n",
    "\n",
    "lasso_model = Lasso()\n",
    "lasso_model.fit(X_train, y_train)\n",
    "# lasso_y_pred = lasso_model.predict(X_test)\n",
    "\n",
    "# https://scikit-learn.ru/3-1-cross-validation-evaluating-estimator-performance/\n",
    "# https://datafinder.ru/products/ocenka-r2-v-mashinnom-obuchenii#:~:text=%D0%9E%D1%86%D0%B5%D0%BD%D0%BA%D0%B0%20R2%20%E2%80%93%20%D0%BE%D1%87%D0%B5%D0%BD%D1%8C%20%D0%B2%D0%B0%D0%B6%D0%BD%D1%8B%D0%B9%20%D0%BF%D0%BE%D0%BA%D0%B0%D0%B7%D0%B0%D1%82%D0%B5%D0%BB%D1%8C,%D0%B2%20%D0%BF%D1%80%D0%BE%D0%B3%D0%BD%D0%BE%D0%B7%D0%B0%D1%85%2C%20%D0%BE%D0%B1%D1%8A%D1%8F%D1%81%D0%BD%D0%B5%D0%BD%D0%BD%D1%8B%D1%85%20%D0%BD%D0%B0%D0%B1%D0%BE%D1%80%D0%BE%D0%BC%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85.\n",
    "# Calculation of R2 Score\n",
    "r2_lr = lr_model.score(X_test, y_test) #cross_val_score(lr_model, X_test, y_test, cv=KFold(n_splits=3), scoring=\"r2\").mean()\n",
    "r2_ridge = ridge_model.score(X_test, y_test) #cross_val_score(ridge_model, X_test, y_test, cv=KFold(n_splits=3), scoring=\"r2\").mean()\n",
    "r2_lasso = lasso_model.score(X_test, y_test) #cross_val_score(lasso_model, X_test, y_test, cv=KFold(n_splits=3), scoring=\"r2\").mean() \n",
    "\n",
    "results_regression.loc[0] = ['LR', 'task2', r2_lr]\n",
    "results_regression.loc[1] = ['Ridge', 'task2', r2_ridge]\n",
    "results_regression.loc[2] = ['Lasso', 'task2', r2_lasso]\n",
    "print(results_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Для Ridge и Lasso подберите коэффициент регуляризации двумя способами 1) GridSearchCV, 2) RidgeCV и LassoCV, в пределах от $10^{-5}$ до $10^5$ (по степеням 10). Посчитайте R2 на тестовой выборке по всем моделям и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['alpha', 'copy_X', 'fit_intercept', 'max_iter', 'normalize', 'positive', 'random_state', 'solver', 'tol'])\n",
      "                model   task        R2\n",
      "0                  LR  task2  0.670642\n",
      "1               Ridge  task2  0.665291\n",
      "2               Lasso  task2  0.534676\n",
      "3  Ridge_GridSearchCV  task3  0.670002\n",
      "4             RidgeCV  task3  0.670002\n",
      "5  Lasso_GridSearchCV  task3  0.670360\n",
      "6             LassoCV  task3  0.670360\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# https://medium.com/nuances-of-programming/%D0%BB%D0%B0%D1%81%D1%81%D0%BE-%D0%B8-%D1%80%D0%B8%D0%B4%D0%B6-%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D0%B8-%D0%B8%D0%BD%D1%82%D1%83%D0%B8%D1%82%D0%B8%D0%B2%D0%BD%D0%BE%D0%B5-%D1%81%D1%80%D0%B0%D0%B2%D0%BD%D0%B5%D0%BD%D0%B8%D0%B5-a542dd761f62\n",
    "### Ваш код ###\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "# Defining grid of candidate alpha values (powers of 10, from 0.00001 to 1000000)\n",
    "param_grid = {\"alpha\": 10.0 ** np.arange(-5, 6)}\n",
    "\n",
    "# Initializing Ridge and GridSearchCV estimators\n",
    "ridge = Ridge()\n",
    "print(ridge.get_params().keys())\n",
    "grid_search = GridSearchCV(estimator=ridge, param_grid=param_grid)\n",
    "# Fitting grid search object\n",
    "grid_search.fit(X_train, y_train)\n",
    "r2_ridge_grid_search = grid_search.score(X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "ridge_reg_cv = RidgeCV(alphas=param_grid['alpha'], cv=5)\n",
    "ridge_reg_cv.fit(X_train, y_train)\n",
    "r2_ridge_cv = ridge_reg_cv.score(X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "# Initializing Lasso and GridSearchCV estimators\n",
    "lasso = Lasso()\n",
    "grid_search_lasso = GridSearchCV(estimator=lasso, param_grid=param_grid)\n",
    "# Fitting grid search object\n",
    "grid_search_lasso.fit(X_train, y_train)\n",
    "r2_lasso_grid_search = grid_search_lasso.score(X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "lasso_reg_cv = LassoCV(alphas=param_grid['alpha'], cv=5)\n",
    "lasso_reg_cv.fit(X_train, y_train)\n",
    "\n",
    "r2_lasso_cv = lasso_reg_cv.score(X_test, y_test)\n",
    "\n",
    "\n",
    "results_regression.loc[3] = ['Ridge_GridSearchCV', 'task3', r2_ridge_grid_search]\n",
    "results_regression.loc[4] = ['RidgeCV', 'task3', r2_ridge_cv]\n",
    "results_regression.loc[5] = ['Lasso_GridSearchCV', 'task3', r2_lasso_grid_search]\n",
    "results_regression.loc[6] = ['LassoCV', 'task3', r2_lasso_cv]\n",
    "print(results_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Проведите масштабирование выборки (используйте Pipeline, StandardScaler, MinMaxScaler), посчитайте R2 для Ridge и Lasso с параметрами по умолчанию и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   model   task        R2\n",
      "0                     LR  task2  0.670642\n",
      "1                  Ridge  task2  0.665291\n",
      "2                  Lasso  task2  0.534676\n",
      "3     Ridge_GridSearchCV  task3  0.670002\n",
      "4                RidgeCV  task3  0.670002\n",
      "5     Lasso_GridSearchCV  task3  0.670360\n",
      "6                LassoCV  task3  0.670360\n",
      "7   Ridge_StandardScaler  task4  0.670844\n",
      "8     Ridge_MinMaxScaler  task4  0.666259\n",
      "9   Lasso_StandardScaler  task4  0.608150\n",
      "10    Lasso_MinMaxScaler  task4  0.094319\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "### Ваш код ###\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "estimators = [('scaler', StandardScaler()), ('model', Ridge())]\n",
    "pipe = Pipeline(estimators)\n",
    "r2_ridge_standart_scaler = pipe.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "estimators = [('scaler', MinMaxScaler()), ('model', Ridge())]\n",
    "pipe = Pipeline(estimators)\n",
    "r2_ridge_min_max_scaler = pipe.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "estimators = [('scaler', StandardScaler()), ('model', Lasso())]\n",
    "pipe = Pipeline(estimators)\n",
    "r2_lasso_standart_scaler = pipe.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "estimators = [('scaler', MinMaxScaler()), ('model', Lasso())]\n",
    "pipe = Pipeline(estimators)\n",
    "r2_lasso_min_max_scaler = pipe.fit(X_train, y_train).score(X_test, y_test)\n",
    "results_regression.loc[7] = ['Ridge_StandardScaler', 'task4', r2_ridge_standart_scaler]\n",
    "results_regression.loc[8] = ['Ridge_MinMaxScaler', 'task4', r2_ridge_min_max_scaler]\n",
    "results_regression.loc[9] = ['Lasso_StandardScaler', 'task4', r2_lasso_standart_scaler]\n",
    "results_regression.loc[10] = ['Lasso_MinMaxScaler', 'task4', r2_lasso_min_max_scaler]\n",
    "print(results_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Подберите коэффициент регуляризации для Ridge и Lasso на масштабированных данных, посчитайте R2 и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      model   task        R2\n",
      "0                        LR  task2  0.670642\n",
      "1                     Ridge  task2  0.665291\n",
      "2                     Lasso  task2  0.534676\n",
      "3        Ridge_GridSearchCV  task3  0.670002\n",
      "4                   RidgeCV  task3  0.670002\n",
      "5        Lasso_GridSearchCV  task3  0.670360\n",
      "6                   LassoCV  task3  0.670360\n",
      "7      Ridge_StandardScaler  task4  0.670844\n",
      "8        Ridge_MinMaxScaler  task4  0.666259\n",
      "9      Lasso_StandardScaler  task4  0.608150\n",
      "10       Lasso_MinMaxScaler  task4  0.094319\n",
      "11  Ridge_StandardScaler_CV  task5  0.671640\n",
      "12    Ridge_MinMaxScaler_CV  task5  0.670629\n",
      "13  Lasso_StandardScaler_CV  task5  0.671214\n",
      "14    Lasso_MinMaxScaler_CV  task5  0.671900\n"
     ]
    }
   ],
   "source": [
    "# print_metrics\n",
    "# plot_prediction\n",
    "\n",
    "### Ваш код ###\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('model', Ridge())])\n",
    "params = { 'model__alpha': 10.0 ** np.arange(-5, 6) }\n",
    "grid_pipeline = GridSearchCV(pipe, params)\n",
    "r2_ridge_standart_scaler_cv = grid_pipeline.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()), ('model', Ridge())])\n",
    "params = { 'model__alpha': 10.0 ** np.arange(-5, 6) }\n",
    "grid_pipeline = GridSearchCV(pipe, params)\n",
    "r2_ridge_min_max_scaler_cv = grid_pipeline.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('model', Lasso())])\n",
    "params = { 'model__alpha': 10.0 ** np.arange(-5, 6) }\n",
    "grid_pipeline = GridSearchCV(pipe, params)\n",
    "r2_lasso_standart_scaler_cv = grid_pipeline.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()), ('model', Lasso())])\n",
    "params = { 'model__alpha': 10.0 ** np.arange(-5, 6) }\n",
    "grid_pipeline = GridSearchCV(pipe, params)\n",
    "r2_lasso_min_max_scaler_cv = grid_pipeline.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "results_regression.loc[11] = ['Ridge_StandardScaler_CV', 'task5', r2_ridge_standart_scaler_cv]\n",
    "results_regression.loc[12] = ['Ridge_MinMaxScaler_CV', 'task5', r2_ridge_min_max_scaler_cv]\n",
    "results_regression.loc[13] = ['Lasso_StandardScaler_CV', 'task5', r2_lasso_standart_scaler_cv]\n",
    "results_regression.loc[14] = ['Lasso_MinMaxScaler_CV', 'task5', r2_lasso_min_max_scaler_cv]\n",
    "print(results_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Добавьте попарные произведения признаков и их квадраты (используйте PolynomialFeatures) на масштабированных признаках, посчитайте R2 для Ridge и Lasso с параметрами по умолчанию и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        model   task        R2\n",
      "0                          LR  task2  0.670642\n",
      "1                       Ridge  task2  0.665291\n",
      "2                       Lasso  task2  0.534676\n",
      "3          Ridge_GridSearchCV  task3  0.670002\n",
      "4                     RidgeCV  task3  0.670002\n",
      "5          Lasso_GridSearchCV  task3  0.670360\n",
      "6                     LassoCV  task3  0.670360\n",
      "7        Ridge_StandardScaler  task4  0.670844\n",
      "8          Ridge_MinMaxScaler  task4  0.666259\n",
      "9        Lasso_StandardScaler  task4  0.608150\n",
      "10         Lasso_MinMaxScaler  task4  0.094319\n",
      "11    Ridge_StandardScaler_CV  task5  0.671640\n",
      "12      Ridge_MinMaxScaler_CV  task5  0.670629\n",
      "13    Lasso_StandardScaler_CV  task5  0.671214\n",
      "14      Lasso_MinMaxScaler_CV  task5  0.671900\n",
      "15  Ridge_StandardScaler_Poly  task6  0.877763\n",
      "16    Ridge_MinMaxScaler_Poly  task6  0.825928\n",
      "17  Lasso_StandardScaler_Poly  task6  0.748369\n",
      "18    Lasso_MinMaxScaler_Poly  task6  0.089644\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "### Ваш код ###\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('poly', PolynomialFeatures()), ('model', Ridge())])\n",
    "r2_ridge_standart_scaler_poly = pipe.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()), ('poly', PolynomialFeatures()), ('model', Ridge())])\n",
    "r2_ridge_min_max_scaler_poly = pipe.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('poly', PolynomialFeatures()), ('model', Lasso())])\n",
    "r2_lasso_standart_scaler_poly = pipe.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()), ('poly', PolynomialFeatures()), ('model', Lasso())])\n",
    "r2_lasso_min_max_scaler_poly = pipe.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "\n",
    "results_regression.loc[15] = ['Ridge_StandardScaler_Poly', 'task6', r2_ridge_standart_scaler_poly]\n",
    "results_regression.loc[16] = ['Ridge_MinMaxScaler_Poly', 'task6', r2_ridge_min_max_scaler_poly]\n",
    "results_regression.loc[17] = ['Lasso_StandardScaler_Poly', 'task6', r2_lasso_standart_scaler_poly]\n",
    "results_regression.loc[18] = ['Lasso_MinMaxScaler_Poly', 'task6', r2_lasso_min_max_scaler_poly]\n",
    "print(results_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Подберите коэффициент регуляризации для Ridge и Lasso на масштабированных данных, добавив PolynomialFeatures, посчитайте R2 и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.495e+02, tolerance: 2.514e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.146e+02, tolerance: 2.574e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.237e+02, tolerance: 2.353e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.350e+02, tolerance: 2.483e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.224e+02, tolerance: 2.507e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.176e+02, tolerance: 2.514e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.085e+02, tolerance: 2.574e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.963e+02, tolerance: 2.353e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.174e+02, tolerance: 2.483e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.036e+02, tolerance: 2.507e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.540e+02, tolerance: 2.514e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.809e+02, tolerance: 2.574e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.445e+02, tolerance: 2.353e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.491e+02, tolerance: 2.483e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.699e+02, tolerance: 2.507e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.440e+01, tolerance: 2.483e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.566e+02, tolerance: 2.514e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.174e+02, tolerance: 2.574e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.928e+02, tolerance: 2.353e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.322e+02, tolerance: 2.483e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.071e+02, tolerance: 2.507e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.728e+02, tolerance: 2.514e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.271e+02, tolerance: 2.574e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.819e+02, tolerance: 2.353e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.307e+02, tolerance: 2.483e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.133e+02, tolerance: 2.507e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.942e+02, tolerance: 2.514e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.024e+02, tolerance: 2.574e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.604e+02, tolerance: 2.353e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.892e+02, tolerance: 2.483e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.958e+02, tolerance: 2.507e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.675e+00, tolerance: 2.514e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.817e+01, tolerance: 2.574e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.101e+00, tolerance: 2.483e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           model   task        R2\n",
      "0                             LR  task2  0.670642\n",
      "1                          Ridge  task2  0.665291\n",
      "2                          Lasso  task2  0.534676\n",
      "3             Ridge_GridSearchCV  task3  0.670002\n",
      "4                        RidgeCV  task3  0.670002\n",
      "5             Lasso_GridSearchCV  task3  0.670360\n",
      "6                        LassoCV  task3  0.670360\n",
      "7           Ridge_StandardScaler  task4  0.670844\n",
      "8             Ridge_MinMaxScaler  task4  0.666259\n",
      "9           Lasso_StandardScaler  task4  0.608150\n",
      "10            Lasso_MinMaxScaler  task4  0.094319\n",
      "11       Ridge_StandardScaler_CV  task5  0.671640\n",
      "12         Ridge_MinMaxScaler_CV  task5  0.670629\n",
      "13       Lasso_StandardScaler_CV  task5  0.671214\n",
      "14         Lasso_MinMaxScaler_CV  task5  0.671900\n",
      "15     Ridge_StandardScaler_Poly  task6  0.877763\n",
      "16       Ridge_MinMaxScaler_Poly  task6  0.825928\n",
      "17     Lasso_StandardScaler_Poly  task6  0.748369\n",
      "18       Lasso_MinMaxScaler_Poly  task6  0.089644\n",
      "19  Ridge_StandardScaler_Poly_CV  task7  0.866597\n",
      "20    Ridge_MinMaxScaler_Poly_CV  task7  0.868587\n",
      "21  Lasso_StandardScaler_Poly_CV  task7  0.852894\n",
      "22    Lasso_MinMaxScaler_Poly_CV  task7  0.840998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.853e+01, tolerance: 3.109e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "### Ваш код ###\n",
    "\n",
    "params = { 'model__alpha': 10.0 ** np.arange(-5, 6) }\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('poly', PolynomialFeatures()), ('model', Ridge())])\n",
    "grid_pipeline = GridSearchCV(pipe, params)\n",
    "r2_ridge_standart_scaler_poly_cv = grid_pipeline.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()), ('poly', PolynomialFeatures()), ('model', Ridge())])\n",
    "grid_pipeline = GridSearchCV(pipe, params)\n",
    "r2_ridge_min_max_scaler_poly_cv = grid_pipeline.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('poly', PolynomialFeatures()), ('model', Lasso())])\n",
    "grid_pipeline = GridSearchCV(pipe, params)\n",
    "r2_lasso_standart_scaler_poly_cv = grid_pipeline.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()), ('poly', PolynomialFeatures()), ('model', Lasso())])\n",
    "grid_pipeline = GridSearchCV(pipe, params)\n",
    "r2_lasso_min_max_scaler_poly_cv = grid_pipeline.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "\n",
    "results_regression.loc[19] = ['Ridge_StandardScaler_Poly_CV', 'task7', r2_ridge_standart_scaler_poly_cv]\n",
    "results_regression.loc[20] = ['Ridge_MinMaxScaler_Poly_CV', 'task7', r2_ridge_min_max_scaler_poly_cv]\n",
    "results_regression.loc[21] = ['Lasso_StandardScaler_Poly_CV', 'task7', r2_lasso_standart_scaler_poly_cv]\n",
    "results_regression.loc[22] = ['Lasso_MinMaxScaler_Poly_CV', 'task7', r2_lasso_min_max_scaler_poly_cv]\n",
    "print(results_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Подберите наилучшую модель (используйте Pipeline, GridSearchCV) подбирая тип регуляризации (L1,L2), коэффициент регуляризации, метод масштабирования и степень полинома в PolynomialFeatures. Выведите итоговые параметры и результат R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Ваш код ###\n",
    "params = { 'model__alpha': 10.0 ** np.arange(-5, 6) }\n",
    "\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('poly', PolynomialFeatures()), ('model', Lasso())])\n",
    "grid_pipeline = GridSearchCV(pipe, params)\n",
    "r2_lasso_standart_scaler_poly_cv = grid_pipeline.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "best_params = {cv: 'GridSearchCV', scaler: 'MinMaxScaler', model: 'Ridge(L2)', best_aplha: grid_pipeline.best_params_, }\n",
    "\n",
    "\n",
    "print('Параметры лучшей модели:\\n', best_params)\n",
    "r2_best_model = 0\n",
    "results_regression.loc[23] = ['Best_Model', 'task8', r2_best_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://archive.ics.uci.edu/ml/datasets/Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<=50K' '>50K']\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('adult.csv')\n",
    "print(data['class'].unique())#.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Разделите выборку на признаки и целевую переменную(колонка class). Замените целевую переменную на числовые значения ('<=50K' - 1, '>50K' - 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Ваш код ###\n",
    "data[\"class-num\"] = np.where(data[\"class\"] == \"<=50K\", 1, 0)\n",
    "y = data[\"class-num\"]\n",
    "X = data.drop(columns=[\"class\", \"class-num\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state = 10, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Посчитайте метрики accuracy и f1_score на предсказании только самого частого класса в целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "### Ваш код ###\n",
    "print(type(X_test))\n",
    "# X_train_most_frequent = X_test[X_test[\"class-num\"] == 1]\n",
    "# y_train_most_frequent = y_test[y_test[\"class-num\"] == 1]\n",
    "\n",
    "f1_most_frequent = 0\n",
    "acc_most_frequent = 0\n",
    "results_classification.loc[0] = ['Most Frequent class', 'task10', f1_most_frequent, acc_most_frequent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Выясните, присутствуют ли в данных пропуски. Если присутствуют, заполните их самыми частыми значениями (испольуйте SimpleImputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
      "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
      "       'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
      "       'class', 'class-num'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "### Ваш код ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Выберите колонки с числовыми и категориальными переменными (используя возможности pandas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks+=1\n",
    "\n",
    "### Ваш код ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Создайте пайплайн по обработке числовых и категориальных значений колонок (используйте OneHotEncoder,MinMaxScaler) и посчитайте cross_val_score по алгоритмам LogisticRegression, KNeighborsClassifier, LinearSVC по метрикам accuracy и f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Ваш код ###\n",
    "\n",
    "f1_LR = 0\n",
    "acc_LR = 0\n",
    "f1_KNN = 0\n",
    "acc_KNN = 0\n",
    "f1_SVM = 0\n",
    "acc_SVM = 0\n",
    "results_classification.loc[1] = ['LogisticRegression', 'task13', f1_LR, acc_LR]\n",
    "results_classification.loc[2] = ['KNeighborsClassifier', 'task13', f1_KNN, acc_KNN]\n",
    "results_classification.loc[3] = ['LinearSVC', 'task13', f1_SVM, acc_SVM]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Можно заметить что в данных присутствуют значения '?', замените их самыми частыми значениями, (испольуйте SimpleImputer). Посчитайте cross_val_score по алгоритмам LogisticRegression, KNeighborsClassifier, LinearSVC по метрикам accuracy и f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Ваш код ###\n",
    "\n",
    "f1_LR = 0\n",
    "acc_LR = 0\n",
    "f1_KNN = 0\n",
    "acc_KNN = 0\n",
    "f1_SVM = 0\n",
    "acc_SVM = 0\n",
    "results_classification.loc[4] = ['LogisticRegression_impute', 'task14', f1_LR, acc_LR]\n",
    "results_classification.loc[5] = ['KNeighborsClassifier_impute', 'task14', f1_KNN, acc_KNN]\n",
    "results_classification.loc[6] = ['LinearSVC_impute', 'task14', f1_SVM, acc_SVM]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Посчитайте cross_val_score по тем же алгоритмам и метрикам, если просто удалить значения '?'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Ваш код ###\n",
    "\n",
    "f1_LR_del_missings = 0\n",
    "acc_LR_del_missings = 0\n",
    "f1_KNN_del_missings = 0\n",
    "acc_KNN_del_missings = 0\n",
    "f1_SVM_del_missings = 0\n",
    "acc_SVM_del_missings = 0\n",
    "results_classification.loc[7] = ['LogisticRegression_delete_missings', 'task15', f1_LR_del_missings, acc_LR_del_missings]\n",
    "results_classification.loc[8] = ['KNeighborsClassifier_delete_missings', 'task15', f1_KNN_del_missings, acc_KNN_del_missings]\n",
    "results_classification.loc[9] = ['LinearSVC_delete_missings', 'task15', f1_SVM_del_missings, acc_SVM_del_missings]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 16. Посчитайте cross_val_score для RandomForestClassifier,GradientBoostingClassifier на данных с замененными значениями '?' на самые частые значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Ваш код ###\n",
    "\n",
    "f1_RF = 0\n",
    "acc_RF = 0\n",
    "f1_GB = 0\n",
    "acc_GB = 0\n",
    "results_classification.loc[10] = ['RandomForestClassifier', 'task16', f1_RF, acc_RF]\n",
    "results_classification.loc[11] = ['GradientBoostingClassifier', 'task16', f1_GB, acc_GB]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. Подберите наилучшую модель, подбирая методы обработки колонок - масштабирование признаков, кодирование признаков и заполнение пропусков. Параметры алгоритмов оставьте по умолчанию. Выведите итоговые параметры и результат accuracy и f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Ваш код ###\n",
    "\n",
    "best_params = {}\n",
    "print('Параметры лучшей модели:\\n', best_params)\n",
    "f1_best = 0\n",
    "acc_best = 0\n",
    "results_classification.loc[12] = ['Best_Model', 'task17', f1_best, acc_best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
